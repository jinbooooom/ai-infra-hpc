 

# CUDA 编程

## 计算机架构

有多种不同的方法可以对计算机架构进行分类。一个广泛使用的分类方法是弗林分类法（Flynn’s Taxonomy），它根据指令和数据进入CPU的方式，将计算机架构分为4种不同的类型（如图1-6所示）。

![image-20240801085949080](assets/readme/image-20240801085949080.png)



- SISD指的是传统计算机：一种串行架构。在这种计算机上只有一个核心。在任何时间点上只有一个指令流在处理一个数据流。

- SIMD是一种并行架构类型。在这种计算机上有多个核心。在任何时间点上所有的核心只有一个指令流处理不同的数据流。向量机是一种典型的SIMD类型的计算机，现在大多数计算机都采用了SIMD架构。SIMD最大的优势或许就是，在CPU上编写代码时，程序员可以继续按串行逻辑思考但对并行数据操作实现并行加速，而其他细节则由编译器来负责。

- MISD类架构比较少见，在这种架构中，每个核心通过使用多个指令流处理同一个数据流。

- MIMD是一种并行架构，在这种架构中，多个核心使用多个指令流来异步处理多个数据流，从而实现空间上的并行性。许多MIMD架构还包括SIMD执行的子组件。

GPU代表了一种众核架构，几乎包括了前文描述的所有并行结构：多线程、MIMD（多指令多数据）、SIMD（单指令多数据），以及指令级并行。NVIDIA公司称这种架构为SIMT（单指令多线程）。

#### GPU核心和CPU核心

尽管可以使用多核和众核来区分CPU和GPU的架构，但这两种核心是完全不同的。

CPU核心比较重，用来处理非常复杂的控制逻辑，以优化串行程序执行。

GPU核心较轻，用于优化具有简单控制逻辑的数据并行任务，注重并行程序的吞吐量。

## cuda 编程模型

### 异构架构

![image-20240801090606975](assets/readme/image-20240801090606975.png)

一个典型的异构计算节点包括两个多核CPU插槽和两个或更多个的众核GPU。GPU不是一个独立运行的平台而是CPU的协处理器。因此，GPU必须通过PCIe总线与基于CPU的主机相连来进行操作，如图1-9所示。这就是为什么CPU所在的位置被称作主机端而GPU 所在的位置被称作设备端。

上图中的ALU指算术逻辑单元，它是CPU的一个重要组成部分。ALU负责执行各种算术和逻辑操作，包括加法、减法、乘法、除法、位运算等。

### 内存层次结构

在GPU内存层次结构中，最主要的两种内存是全局内存和共享内存。全局类似于CPU的系统内存，而共享内存类似于CPU的缓存。然而GPU的共享内存可以由CUDA C的内核直接控制

<img src="assets/readme/image-20240806151436569.png" alt="image-20240806151436569" style="zoom:50%;" />

### 线程管理

当核函数在主机端启动时，它的执行会移动到设备上，此时设备中会产生大量的线程并且每个线程都执行由核函数指定的语句。了解如何组织线程是CUDA编程的一个关键部分。CUDA明确了线程层次抽象的概念以便于你组织线程。这是一个两层的线程层次结构，由线程块和线程块网格构成，如图2-5所示。

<img src="assets/readme/image-20240806152148149.png" alt="image-20240806152148149" style="zoom:50%;" />



由一个内核启动所产生的所有线程统称为一个网格。同一网格中的所有线程共享相同的全局内存空间。一个网格由多个线程块构成，一个线程块包含一组线程，同一线程块内的线程可以通过共享内存的方式来协作。不同块内的线程不能协作。

线程依靠以下两个坐标变量来区分彼此。

- blockIdx（线程块在线程格内的索引）
- threadIdx（块内的线程索引）

### 函数类型限定符

函数类型限定符指定一个函数在主机上执行还是在设备上执行，以及可被主机调用还是被设备调用

![image-20240815181902730](assets/readme/image-20240815181902730.png)

#### CUDA核函数的限制

以下限制适用于所有核函数：

- 只能访问设备内存
- 必须具有void返回类型
- 不支持可变数量的参数
- 不支持静态变量
- 显示异步行为

## cuda 执行模型

## 内存布局

![image-20241226154917460](assets/readme/image-20241226154917460.png)

### 寄存器

在 CUDA 编程中，局部变量默认存储在寄存器中（如果寄存器足够）。例如：

```cpp
__global__ void kernel(int *data) {
    int tid = threadIdx.x;  // tid 存储在寄存器中
    int temp = data[tid];   // temp 存储在寄存器中
    temp = temp * 2;        // 使用寄存器中的数据进行计算
    data[tid] = temp;       // 将结果写回全局内存
}
```

在上面的代码中：

- `tid` 和 `temp` 是局部变量，默认存储在寄存器中。
- 如果寄存器不足，编译器会将部分变量存储在本地内存

寄存器是 GPU 内存布局中最快、最接近计算核心的内存类型，用于存储线程的临时变量和中间计算结果。寄存器的访问速度极快，但容量有限。合理利用寄存器可以显著提高 GPU 程序的性能，而寄存器溢出（变量被存储在本地内存中）会导致性能下降。

寄存器溢出（**寄存器不足时的处理**）：如果线程使用的寄存器数量超过了硬件限制，编译器会将部分变量存储在 **本地内存（Local Memory）** 中。本地内存实际上是全局内存的一部分，访问速度比寄存器慢得多。

####  寄存器的容量

在 NVIDIA GPU 中，每个线程可以使用的寄存器数量是有限的，具体数量取决于 GPU 架构和编译器的配置。例如：

- **NVIDIA Tesla V100**（Volta 架构）：每个线程最多可以使用 **255 个寄存器**。
- **NVIDIA A100**（Ampere 架构）：每个线程最多可以使用 **255 个寄存器**。
- 较旧的架构（如 Kepler、Maxwell）可能支持更少的寄存器。

#### **寄存器的大小**

在 GPU 和大多数现代计算机体系结构中，**一个寄存器通常是 4 字节（32 位）**，这是由硬件设计、历史演变和应用需求共同决定的。以下是原因：

- **数据对齐和效率**

  - **4 字节对齐**：现代计算机体系结构通常以 4 字节为单位进行数据对齐，这样可以提高内存访问效率。

  - **硬件优化**：32 位寄存器的设计可以高效地处理整数、浮点数和其他常见数据类型，同时简化硬件电路的设计。

- **指令集架构**

  - **32 位指令集**：许多现代处理器（如 x86、ARM、NVIDIA GPU）使用 32 位指令集，寄存器的大小与指令集匹配，可以简化指令解码和执行。

  - **通用性**：32 位寄存器可以处理 8 位（char）、16 位（short）、32 位（int）和 64 位（long long）数据类型，具有较好的通用性

## 流和并发
